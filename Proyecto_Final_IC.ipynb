{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proyecto Final IC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Miguel2900/IC/blob/main/Proyecto_Final_IC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dNbUHtE1jBX-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.datasets.mnist import load_data as dataNum\n",
        "from tensorflow.keras.datasets.cifar10 import load_data as dataImg\n",
        "\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(numTrnData,numTrnCategories),(numTstData,numTstCategories)=dataNum()\n",
        "(imgTrnData,imgTrnCategories),(imgTstData,imgTstCategories)=dataImg()"
      ],
      "metadata": {
        "id": "6XXqyQKikaKq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numTrnData=numTrnData.reshape(numTrnData.shape[0],28,28,1)\n",
        "numTstData=numTstData.reshape(numTstData.shape[0],28,28,1)\n",
        "numFormat=numTrnData.shape[1:]\n",
        "\n",
        "imgTrnData=np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in imgTrnData])\n",
        "imgTstData=np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in imgTstData])\n",
        "imgTrnData=imgTrnData.reshape(imgTrnData.shape[0],32,32,1)\n",
        "imgTstData=imgTstData.reshape(imgTstData.shape[0],32,32,1)\n",
        "imgFormat=imgTrnData.shape[1:]\n",
        "\n",
        "numTstData.reshape(numTstData.shape[0],28,28,1)\n",
        "\n",
        "numTrnData=numTrnData.astype('float32')/255.0\n",
        "numTstData=numTstData.astype('float32')/255.0\n",
        "\n",
        "imgTrnData=imgTrnData.astype('float32')/255.0\n",
        "imgTstData=imgTstData.astype('float32')/255.0"
      ],
      "metadata": {
        "id": "nRId2N5Mki_k"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagenNum = ImageDataGenerator(\n",
        "    rotation_range = 30,\n",
        "    width_shift_range = 0.25,\n",
        "    height_shift_range = 0.25,\n",
        "    zoom_range=[0.5,1.5],\n",
        ")\n",
        "datagenImg = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "datagenNum.fit(numTrnData)\n",
        "datagenImg.fit(imgTrnData)\n",
        "\n",
        "numTrnDataDAD = datagenNum.flow(numTrnData, numTrnCategories, batch_size=32)\n",
        "imgTrnDataDAD = datagenImg.flow(imgTrnData, imgTrnCategories, batch_size=32)"
      ],
      "metadata": {
        "id": "AjQfzChBoKSE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numRegular=Sequential([\n",
        "    Flatten(input_shape=(numFormat)), \n",
        "    Dense(units=50, activation='relu',kernel_initializer='he_uniform'),\n",
        "    Dense(units=50, activation='relu',kernel_initializer='he_uniform'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "numConv=Sequential([\n",
        "    Conv2D(32,(3,3),activation='relu',kernel_initializer='he_uniform',input_shape=numFormat),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64,(3,3),activation='relu',kernel_initializer='he_uniform'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "numConvDAD=Sequential([\n",
        "    Conv2D(32,(3,3),activation='relu',kernel_initializer='he_uniform',input_shape=numFormat),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64,(3,3),activation='relu',kernel_initializer='he_uniform'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "numRegular.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "numConv.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "numConvDAD.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Xs0P5Ck9oVNb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgRegular=Sequential([\n",
        "    Flatten(input_shape=(imgFormat)), \n",
        "    Dense(units=50, activation='relu',kernel_initializer='he_uniform'),\n",
        "    Dense(units=50, activation='relu',kernel_initializer='he_uniform'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "imgConv=Sequential([\n",
        "    Conv2D(32,(3,3),activation='relu',kernel_initializer='he_uniform',input_shape=imgFormat),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64,(3,3),activation='relu',kernel_initializer='he_uniform'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "imgConvDAD=Sequential([\n",
        "    Conv2D(32,(3,3),activation='relu',kernel_initializer='he_uniform',input_shape=imgFormat),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64,(3,3),activation='relu',kernel_initializer='he_uniform'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(128,(3,3),activation='relu',kernel_initializer='he_uniform'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "imgRegular.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "imgConv.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "imgConvDAD.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Hf2lYF7CwFAS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch=60\n",
        "batch=128\n",
        "\n",
        "numRegular.fit(numTrnData,numTrnCategories,validation_split=0.25,epochs=epoch,batch_size=batch,verbose=1,use_multiprocessing=True)\n",
        "numConv.fit(numTrnData,numTrnCategories,validation_split=0.25,epochs=epoch,batch_size=batch,verbose=1,use_multiprocessing=True)\n",
        "numConvDAD.fit(numTrnDataDAD,epochs=epoch,batch_size=batch,verbose=1,use_multiprocessing=True)\n",
        "\n",
        "imgRegular.fit(imgTrnData,imgTrnCategories,validation_split=0.25,epochs=epoch,batch_size=batch,verbose=1,use_multiprocessing=True)\n",
        "imgConv.fit(imgTrnData,imgTrnCategories,validation_split=0.25,epochs=epoch,batch_size=batch,verbose=1,use_multiprocessing=True)\n",
        "imgConvDAD.fit(imgTrnDataDAD,epochs=epoch,batch_size=batch,verbose=1,use_multiprocessing=True)"
      ],
      "metadata": {
        "id": "wB_iyY0CwrfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numRegular.evaluate(numTstData,numTstCategories,verbose=1)\n",
        "numConv.evaluate(numTstData,numTstCategories,verbose=1)\n",
        "numConvDAD.evaluate(numTstData,numTstCategories,verbose=1)\n",
        "\n",
        "imgRegular.evaluate(imgTstData,imgTstCategories,verbose=1)\n",
        "imgConv.evaluate(imgTstData,imgTstCategories,verbose=1)\n",
        "imgConvDAD.evaluate(imgTstData,imgTstCategories,verbose=1)"
      ],
      "metadata": {
        "id": "UPEntS7I4iBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numRegular.save('numRegular.h5')\n",
        "numConv.save('numConv.h5')\n",
        "numConvDAD.save('numConvDAD.h5')\n",
        "\n",
        "imgRegular.save('imgRegular.h5')\n",
        "imgConv.save('imgConv.h5')\n",
        "imgConvDAD.save('imgConvDAD.h5')"
      ],
      "metadata": {
        "id": "8Q_8uSffeDV1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs\n",
        "!mkdir numRegular\n",
        "!tensorflowjs_converter --input_format keras numRegular.h5 output\n",
        "\n",
        "!mkdir numConv\n",
        "!tensorflowjs_converter --input_format keras numConv.h5 numConv\n",
        "\n",
        "!mkdir numConvDAD\n",
        "!tensorflowjs_converter --input_format keras numConvDAD.h5 numConvDAD\n",
        "\n",
        "!mkdir imgRegular\n",
        "!tensorflowjs_converter --input_format keras imgRegular.h5 imgRegular\n",
        "\n",
        "!mkdir imgConv\n",
        "!tensorflowjs_converter --input_format keras imgConv.h5 imgConv\n",
        "\n",
        "!mkdir imgConvDAD\n",
        "!tensorflowjs_converter --input_format keras imgConvDAD.h5 imgConvDAD"
      ],
      "metadata": {
        "id": "bLmygDcCeq8C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}